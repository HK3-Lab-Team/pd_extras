{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trousse.dataset import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s \\t %(levelname)s \\t Module: %(module)s \\t %(message)s ',\n",
    "                    datefmt='%d-%b-%y %H:%M:%S', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load DataFrame from Anonymized .csv\n",
    "Create object with some infos about the dataframe\n",
    "\n",
    "We also define some metadata columns manually (referring to the patient identity -> not defined by clinical exams)\n",
    "\n",
    "Their list is retrieved by copying the first 31 columns of the 'Sani_15300_anonym.csv'\n",
    "\n",
    "We use these information to isolate the clinical exams features that can be used for partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This following list is copied and pasted directly from .csv file from the first row (it may be automatized, \n",
    "# but this offers visual control)\n",
    "metadata_cols = \"GROUPS\tTAG\tDATA_SCHEDA\tNOME\tID_SCHEDA\tCOMUNE\tPROV\tMONTH\tYEAR\tBREED\tSEX\tAGE\tSEXUAL STATUS\tBODYWEIGHT\tPULSE RATE\tRESPIRATORY RATE\tTEMP\tBLOOD PRESS MAX\tBLOOD PRESS MIN\tBLOOD PRESS MEAN\tBODY CONDITION SCORE\tHT\tH\tDEATH\tTIME OF DEATH\tPROFILO_PAZIENTE\tANAMNESI_AMBIENTALE\tANAMNESI_ALIMENTARE\tVACCINAZIONI\tFILARIOSI\tGC_SEQ\"\n",
    "metadata_cols = set(metadata_cols.replace('\\t',',').split(','))\n",
    "metadata_cols = metadata_cols.union({'FILARIOSI', 'PROFILO_PAZIENTE'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "CWD = os.getcwd()\n",
    "DATA_PATH = os.path.join(CWD, \"..\", \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sani_dir = os.path.join(DATA_PATH, 'Sani_15300_anonym.csv')\n",
    "# df_correct_dir = os.path.join('data', 'df_correct.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lorenzo-hk3lab/anaconda3/envs/pytorch/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3331: DtypeWarning: Columns (16,17,18,19,31,37,38,40,44,45,56,57,58,59,60,61,62,63,64,65,74,81,82,86,88,93,94,98,99,100,122,123,138,144,145,146,151,152,154,155,156,158) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "28-May-20 17:31:43 \t INFO \t Module: dataframe_with_info \t Data imported from file successfully \n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(metadata_cols=metadata_cols, data_file=df_sani_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct some errors in DF \n",
    "We look for:\n",
    "- Columns where we have different types mixed up\n",
    "- Columns that are not float or int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.refactoring.row_fix import RowFix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28-May-20 17:32:11 \t INFO \t Module: row_fix \t Osmolal Gap is converted from String to Numeric. Lost values are: \n",
      "{'ASSENTI', 'PRESENTI'} \n",
      "28-May-20 17:32:11 \t INFO \t Module: row_fix \t TLI is converted from String to Numeric. Lost values are: \n",
      "{'>100', '>50.0'} \n",
      "28-May-20 17:32:11 \t INFO \t Module: row_fix \t pH (quantitative) is converted from String to Numeric. Lost values are: \n",
      "{'8.0.'} \n",
      "28-May-20 17:32:11 \t INFO \t Module: row_fix \t Serum Total Bilirubin is converted from String to Numeric. Lost values are: \n",
      "{'0-22'} \n",
      "28-May-20 17:32:11 \t INFO \t Module: row_fix \t Lipase/Crea is converted from String to Numeric. Lost values are: \n",
      "{'PRESENTI'} \n",
      "28-May-20 17:32:11 \t INFO \t Module: row_fix \t D Dimer is converted from String to Numeric. Lost values are: \n",
      "{'0.0.6'} \n"
     ]
    }
   ],
   "source": [
    "fix_tool = RowFix()\n",
    "df_correct = fix_tool.fix_common_errors(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Rows with initial mistakes: 63\n",
      "\n",
      " Total:  BEFORE: 155 errors  -->  AFTER: 3 errors\n"
     ]
    }
   ],
   "source": [
    "fix_tool.count_errors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The errors per feature are:\n",
      "TTKG: 2 : {'ASSENTI'} ---> 0 : set()\n",
      "Serum PON-1: 1 : {'-'} ---> 0 : set()\n",
      "MONOCYTE: 17 : {'3%', '10%', '6%', '8%', '4%', '2%', '5%', '7%'} ---> 0 : set()\n",
      "PUCU: 1 : {'ASSENTI'} ---> 0 : set()\n",
      "EOSINOPHIL: 17 : {'3%', '10%', '1%', '6%', '8%', '0%', '2%', '5%'} ---> 0 : set()\n",
      "Bile Acids/Crea: 1 : {'ASSENTI'} ---> 0 : set()\n",
      "EF Posphate: 2 : {'ASSENTI'} ---> 0 : set()\n",
      "VolLTTHY: 1 : {'0,68'} ---> 0 : set()\n",
      "BASOPHIL: 16 : {'0%'} ---> 0 : set()\n",
      "D Dimer: 2 : {'0.0.6', '0,03'} ---> 1 : {'0.0.6'}\n",
      "Plasma Lactate: 3 : {'1,3', '19,6', '-'} ---> 0 : set()\n",
      "pH (quantitative): 2 : {'8,9', '8.0.'} ---> 1 : {'8.0.'}\n",
      "Amylase/Crea: 1 : {'PRESENTI'} ---> 0 : set()\n",
      "Serum Total Protein: 1 : {'6,4'} ---> 0 : set()\n",
      "Fibrinogen: 3 : {'<60'} ---> 0 : set()\n",
      "Bilirubin/Crea: 1 : {'PRESENTI'} ---> 0 : set()\n",
      "EF Potassium: 2 : {'ASSENTI'} ---> 0 : set()\n",
      "TT4: 1 : {'-'} ---> 0 : set()\n",
      "FT4: 3 : {'<3.86', '---', '-'} ---> 0 : set()\n",
      "Serum Ferritin: 1 : {'Error'} ---> 0 : set()\n",
      "TSH: 4 : {'<0.030', '---'} ---> 0 : set()\n",
      "EF Calcium: 2 : {'ASSENTI'} ---> 0 : set()\n",
      "EF Urea: 2 : {'ASSENTI'} ---> 0 : set()\n",
      "LIMPHOCYTE: 17 : {'24%', '34%', '15%', '12%', '28%', '16%', '19%', '49%', '40%', '21%', '20%', '26%', '13%'} ---> 0 : set()\n",
      "Activated Partial thromboplastin Time: 2 : {'>240.0'} ---> 0 : set()\n",
      "EF Sodium: 2 : {'ASSENTI'} ---> 0 : set()\n",
      "AMMONIUM: 9 : {'---'} ---> 0 : set()\n",
      "Quantitative FDP: 3 : {'>150.0', '>150', '>150.00'} ---> 0 : set()\n",
      "Serum Total Bilirubin: 2 : {'---', '0-22'} ---> 1 : {'0-22'}\n",
      "Specific gravity: 5 : {'ASSENTI', '>1060'} ---> 0 : set()\n",
      "Serum Total Carbon Dioxide: 1 : {'22,8'} ---> 0 : set()\n",
      "NEUTROPHIL: 17 : {'66%', '60%', '52%', '77%', '69%', '72%', '74%', '76%', '80%', '78%', '58%', '65%', '48%'} ---> 0 : set()\n",
      "Prothrombin Time: 3 : {'>120.0'} ---> 0 : set()\n",
      "Osmolality: 1 : {'ASSENTI'} ---> 0 : set()\n",
      "Thrombin Time: 3 : {'>240.0'} ---> 0 : set()\n",
      "Measured Osmolaity: 1 : {'ASSENTI'} ---> 0 : set()\n",
      "Serum GGT: 1 : {'2,6'} ---> 0 : set()\n",
      "EF Chloride: 2 : {'ASSENTI'} ---> 0 : set()\n"
     ]
    }
   ],
   "source": [
    "fix_tool.print_errors_per_column()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from utils.refactoring import feature_fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correct = feature_fix.encode_single_categorical_column(df_correct, col_name='FILARIOSI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('FILARIOSI_enc',)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_correct.find_encoded_column('FILARIOSI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<utils.dataframe_with_info.FeatureOperation at 0x7fef6d348d00>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_correct.feature_elaborations['FILARIOSI_enc'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create age_partition column to split age intervals in three parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correct = feature_fix.split_continuous_column_into_bins(df_correct, col_name='AGE', bin_threshold=[12, 84])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look for the encoded column derived from 'AGE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.refactoring.feature_enum import OperationTypeEnum\n",
    "from utils.dataframe_with_info import FeatureOperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_on_age = df_correct.find_operation_in_column(feat_operation=FeatureOperation(original_columns='AGE', operation_type=OperationTypeEnum.BIN_SPLITTING))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        2\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "15212    2\n",
       "15213    1\n",
       "15214    1\n",
       "15215    1\n",
       "15216    2\n",
       "Name: AGE_bin_id, Length: 15217, dtype: int8"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_correct.df[operation_on_age.derived_columns[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may want to retrieve informations about what has been done.\n",
    "We select the first operation because it is the only present"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple combination of categorical columns (metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.refactoring import feature_fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_cols = ['SEX', 'SEXUAL STATUS', 'AGE_bin_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output, new_columns = \\\n",
    "    feature_fix.make_categorical_columns_multiple_combinations(df_correct, col_names=partition_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set column to datetime (ADD to library functionalities!!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Convert to datetime\n",
    "dataset.df['DATA_SCHEDA'] = pd.to_datetime(dataset.df['DATA_SCHEDA'], format='%m/%d/%Y')\n",
    "dataset.df['AGE'] = dataset.df['AGE'].astype(np.int16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export and import of df_correct instance to file using 'shelve'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correct.to_file(os.path.join(DATA_PATH, 'df_correct_dump'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-Local",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}